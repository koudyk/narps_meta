{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title\n",
    "Kendra Oudyk \\\n",
    "NEUR608 Neuroimaging Data Science\\\n",
    "McGill University\\\n",
    "Drs. Boris Bernhardt and Bratislav Misic, instructors\\\n",
    "2019-10-28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda-latest/envs/neuro_py36/lib/python3.6/importlib/_bootstrap_external.py:922: FutureWarning: Module nipy.labs.utils.routines deprecated, will be removed\n",
      "  _imp.create_dynamic, spec)\n",
      "/opt/miniconda-latest/envs/neuro_py36/lib/python3.6/site-packages/nipy/labs/statistical_mapping.py:15: FutureWarning: Module nipy.labs.glm deprecated, will be removed. Please use nipy.modalities.fmri.glm instead.\n",
      "  from .glm import glm\n",
      "/opt/miniconda-latest/envs/neuro_py36/lib/python3.6/site-packages/nipy/labs/statistical_mapping.py:16: FutureWarning: Module nipy.labs.group deprecated, will be removed\n",
      "  from .group.permutation_test import \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191028-20:04:56,81 nipype.utils INFO:\n",
      "\t Running nipype version 1.2.3 (latest: 1.2.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nipype.utils:Running nipype version 1.2.3 (latest: 1.2.3)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "import nilearn\n",
    "import numpy as np\n",
    "from nilearn import masking, plotting\n",
    "from nipy.labs.statistical_mapping import get_3d_peaks\n",
    "import nibabel as nib\n",
    "import scipy\n",
    "from matplotlib import pyplot as plt\n",
    "import ntpath\n",
    "from nimare.dataset import Dataset\n",
    "import nimare\n",
    "import copy\n",
    "from nistats import thresholding\n",
    "\n",
    "level = .05\n",
    "height_control = 'fdr'\n",
    "cluster_threshold = 1\n",
    "\n",
    "template = nilearn.datasets.load_mni152_template()\n",
    "Ni, Nj, Nk = template.shape\n",
    "affine = template.affine\n",
    "gray_mask = masking.compute_gray_matter_mask(template)\n",
    "\n",
    "cut_coords=(0, 0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does the data look like?\n",
    "First, we need to get the paths for the unthresholded image for each analysis team, for the given hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = 'data-narps/proc/'\n",
    "img_paths_full = []\n",
    "i = 0\n",
    "\n",
    "while True:\n",
    "    path = os.path.abspath(f'{input_dir}hypo1_unthresh_{i}.nii.gz')\n",
    "    \n",
    "    if not os.path.isfile(path):\n",
    "        break\n",
    "    \n",
    "    img_paths_full.append(path)\n",
    "    i += 1\n",
    "N_img = 10\n",
    "img_paths = img_paths_full[:N_img]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coordinate-based meta-analysis\n",
    "Using Activation Likelihood Estimateion (ALE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activations(path, threshold, space='ijk'):\n",
    "    \"\"\"\n",
    "    Retrieve the activation coordinates from an image.\n",
    "\n",
    "    Args:\n",
    "        path (string or Nifti1Image): Path to or object of a\n",
    "            nibabel.Nifti1Image from which to extract coordinates.\n",
    "        threshold (float): Peaks under this threshold will not be detected.\n",
    "        space (string): Space of coordinates. Available : 'ijk' and 'pos'.\n",
    "\n",
    "    Returns:\n",
    "        (tuple): Size 3 tuple of np.array storing respectively the X, Y and\n",
    "            Z coordinates\n",
    "\n",
    "    \"\"\"\n",
    "    I, J, K = [], [], []\n",
    "    try:\n",
    "        img = nilearn.image.load_img(path)\n",
    "    except ValueError:  # File path not found\n",
    "        print(f'File {path} not found. Ignored.')\n",
    "        return None\n",
    "\n",
    "    if np.isnan(img.get_fdata()).any():\n",
    "        print(f'Img {path} contains Nan. Ignored.')\n",
    "        return None\n",
    "\n",
    "    img = nilearn.image.resample_to_img(img, template)\n",
    "\n",
    "    peaks = get_3d_peaks(img, mask=gray_mask, threshold=threshold)\n",
    "\n",
    "    if not peaks:\n",
    "        return None\n",
    "\n",
    "    for peak in peaks:\n",
    "        I.append(peak[space][0])\n",
    "        J.append(peak[space][1])\n",
    "        K.append(peak[space][2])\n",
    "\n",
    "    del peaks\n",
    "    \n",
    "    I, J, K = np.array(I), np.array(J), np.array(K)\n",
    "    if space == 'ijk':\n",
    "        I, J, K = I.astype(int), J.astype(int), K.astype(int)\n",
    "        \n",
    "    return I, J, K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fdr_thresholds = [thresholding.map_threshold(path, level=.05, \\\n",
    "                    height_control='fdr')[1] for path in img_paths]\n",
    "\n",
    "activation_peaks = [get_activations(path, fdr_thresholds[n_path], space='ijk') \\\n",
    "                    for n_path,path in enumerate(img_paths)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store peak coordinates in a binary image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-9d59f3689674>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbinary_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mactivation_peaks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNifti1Image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maffine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "binary_imgs = []\n",
    "for I, J, K in activation_peaks:\n",
    "    arr = np.zeros(template.shape)\n",
    "    arr[I, J, K] = 1\n",
    "    img = nib.Nifti1Image(arr, affine)\n",
    "    binary_imgs.append(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize some raw z-maps, thersholded z-maps, and peak activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for n_study in range(len(img_paths)):\n",
    "    # Raw z-map\n",
    "    z_map = img_paths[n_study]\n",
    "    plotting.plot_stat_map(z_map, cut_coords=cut_coords, threshold='auto', title='Team %d: Raw z map' %(n_study+1))\n",
    "\n",
    "    # Thresholded z-map (FDR-corrected)\n",
    "    thresholded_map, threshold = thresholding.map_threshold(z_map, level=level, \n",
    "                       height_control=height_control, cluster_threshold=cluster_threshold)\n",
    "                                                    \n",
    "    plotting.plot_stat_map(thresholded_map, cut_coords=cut_coords,\\\n",
    "                           title='Team %d: Thresholded z-map (FDR-corrected)' %(n_study+1))    \n",
    "    \n",
    "    # Peak activation map\n",
    "    plotting.plot_roi(binary_imgs[n_study], cut_coords=cut_coords,\\\n",
    "                      title='Team %d: Peak activations' %(n_study+1))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform meta-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following functions are used only to convert the input images to a NiMARE input format for IBMA analysis. \n",
    "# These functions also extract peaks coordinates from full images for CBMA analysis.\n",
    "# The understanding of these functions is not crucial.\n",
    "def get_sub_dict(XYZ, path_dict, sample_size):\n",
    "    \"\"\"\n",
    "    Build sub dictionnary of a study using the nimare structure.\n",
    "\n",
    "    Args:\n",
    "        XYZ (tuple): Size 3 tuple of list storing the X Y Z coordinates.\n",
    "        path_dict (dict): Dict which has map name ('t', 'z', 'con', 'se')\n",
    "            as keys and absolute path to the image as values.\n",
    "        sample_size (int): Number of subjects.\n",
    "\n",
    "    Returns:\n",
    "        (dict): Dictionary storing the coordinates for a\n",
    "            single study using the Nimare structure.\n",
    "\n",
    "    \"\"\"\n",
    "    d = {\n",
    "        'contrasts': {\n",
    "            '0': {\n",
    "                'metadata': {'sample_sizes': 119}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    if XYZ is not None:\n",
    "        d['contrasts']['0']['coords'] = {\n",
    "                    'x': list(XYZ[0]),\n",
    "                    'y': list(XYZ[1]),\n",
    "                    'z': list(XYZ[2]),\n",
    "                    'space': 'MNI'\n",
    "                    }\n",
    "        d['contrasts']['0']['sample_sizes'] = sample_size\n",
    "\n",
    "    if path_dict is not None:\n",
    "        d['contrasts']['0']['images'] = path_dict\n",
    "\n",
    "    return d\n",
    "\n",
    "\n",
    "def extract_from_paths(paths, sample_size, data=['coord', 'path'], level=.05, \n",
    "                       height_control='fdr', cluster_threshold=None):\n",
    "    \"\"\"\n",
    "    Extract data (coordinates, paths...) from the data and put it in a\n",
    "        dictionnary using Nimare structure.\n",
    "\n",
    "    Args:\n",
    "        path_dict (dict): Dict which keys are study names and values\n",
    "            absolute paths (string).\n",
    "        data (list): Data to extract. 'coord' and 'path' available.\n",
    "        sample_size (int): Number of subjects in the experiment. \n",
    "        threshold (float): value below threshold are ignored. Used for\n",
    "            peak detection.\n",
    "\n",
    "    Returns:\n",
    "        (dict): Dictionnary storing the coordinates using the Nimare\n",
    "            structure.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Computing a new dataset dictionary\n",
    "    def extract_pool(path):\n",
    "        \"\"\"Extract activation for multiprocessing.\"\"\"\n",
    "        #print(f'Extracting {path}...')\n",
    "        \n",
    "        threshold = thresholding.map_threshold(path, level=level, \\\n",
    "                    height_control=height_control, cluster_threshold=cluster_threshold)[1]\n",
    "\n",
    "        XYZ = None\n",
    "        if 'coord' in data:\n",
    "            XYZ = get_activations(path, threshold, space='pos')\n",
    "            if XYZ is None:\n",
    "                return\n",
    "\n",
    "        if 'path' in data:\n",
    "            base, filename = ntpath.split(path)\n",
    "            file, ext = filename.split('.', 1)\n",
    "\n",
    "            path_dict = {'z': path}\n",
    "            for map_type in ['t', 'con', 'se']:\n",
    "                file_path = f'{base}/{file}_{map_type}.{ext}'\n",
    "                if os.path.isfile(file_path):\n",
    "                    path_dict[map_type] = file_path\n",
    "\n",
    "            return get_sub_dict(XYZ, path_dict, sample_size)\n",
    "\n",
    "        if XYZ is not None:\n",
    "            return get_sub_dict(XYZ, None, sample_size)\n",
    "\n",
    "        return\n",
    "\n",
    "    n_jobs = multiprocessing.cpu_count()\n",
    "    res = Parallel(n_jobs=n_jobs, backend='threading')(\n",
    "        delayed(extract_pool)(path) for path in paths)\n",
    "\n",
    "    # Removing potential None values\n",
    "    res = list(filter(None, res))\n",
    "    \n",
    "    # Merging all dictionaries\n",
    "    return {k: v for k, v in enumerate(res)}\n",
    "\n",
    "\n",
    "def run_ALE(ds_dict):\n",
    "    \"\"\"Run ALE on given data.\"\"\"\n",
    "    ds = Dataset(ds_dict)\n",
    "    ma = nimare.meta.cbma.ale.ALE()\n",
    "    res = ma.fit(ds)\n",
    "\n",
    "    img_ale = res.get_map('ale')\n",
    "    img_p = res.get_map('p')\n",
    "    img_z = res.get_map('z')\n",
    "\n",
    "    return img_ale, img_p, img_z\n",
    "\n",
    "def run_MFX_GLM(ds_dict):\n",
    "    \"\"\"Run MFX_GLM on given data.\"\"\"\n",
    "    ds = Dataset(ds_dict)\n",
    "    ma = nimare.meta.ibma.MFX_GLM()\n",
    "    res = ma.fit(ds)\n",
    "\n",
    "    return res.get_map('t')\n",
    "\n",
    "def run_Fishers(ds_dict):\n",
    "    \"\"\"Run Fishers on given data.\"\"\"\n",
    "    ds = Dataset(ds_dict)\n",
    "    ma = nimare.meta.ibma.Fishers()\n",
    "    res = ma.fit(ds)\n",
    "\n",
    "    return res.get_map('z')\n",
    "\n",
    "def fdr_threshold(img_list, img_p, q=0.05):\n",
    "    \"\"\"Compute FDR and threshold same-sized images.\"\"\"\n",
    "    arr_list = [copy.copy(img.get_fdata()) for img in img_list]\n",
    "    arr_p = img_p.get_fdata()\n",
    "    aff = img_p.affine\n",
    "\n",
    "    fdr = nimare.stats.fdr(arr_p.ravel(), q=q)\n",
    "\n",
    "    for arr in arr_list:\n",
    "        arr[arr_p > fdr] = 0\n",
    "\n",
    "    res_list = [nib.Nifti1Image(arr, aff) for arr in arr_list]\n",
    "\n",
    "    return res_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dict = extract_from_paths(img_paths_full, data=['path', 'coord'], sample_size=119, \n",
    "                    level=level, height_control=height_control, cluster_threshold=cluster_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unthresholded ALE image\n",
    "img_ale, img_p, img_z = run_ALE(ds_dict)\n",
    "\n",
    "# Thresholded ALE image\n",
    "img_ale_thr, img_p_thr, img_z_thr = fdr_threshold([img_ale, img_p, img_z], img_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fisher's\n",
    "img_z_F = run_Fishers(ds_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cut_coords=(21, -32, 64)\n",
    "\n",
    "meta_analysis = { \n",
    "    'ALE': img_ale,\n",
    "    'ALE thresholded': img_ale_thr,\n",
    "    'z Fishers': img_z_F,\n",
    "}\n",
    "\n",
    "for name, img in meta_analysis.items():\n",
    "    plotting.plot_stat_map(img, title=name, cut_coords=cut_coords,\n",
    "                           figure=plt.figure(figsize=(10,5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image-based meta-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
